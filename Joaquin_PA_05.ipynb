{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940d65bc-011d-4762-8f7c-d628f2a81bcd",
   "metadata": {},
   "source": [
    "# Programming Assignment #5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ccdfcc-83fa-4eb2-a3b7-9671f72157e8",
   "metadata": {},
   "source": [
    "## Association rule mining \n",
    "\n",
    "The market basket transactions dataset (transactions_data.txt)contains list of items purchased by customer in each transaction.\n",
    "\n",
    "- load the transaction dataset file\n",
    "- use minimum support = 0.2 and use_colname=True in apriori method \n",
    "- select metric as confidence in association rules\n",
    "- use minimum threshold = 0.5\n",
    "\n",
    "Ex: If the minimum support is 0.4, the metric is confidence and minimum threshold is 0.5 then some of the outputs are: \n",
    "- the least frequency of frequent 1-itemset is ['Queso'].\n",
    "- the support, confidence, and lift of rule, ['Queso'] -> ['Tortilla chips'] are:\n",
    "  - consequent support = 0.7\n",
    "  - support = 0.4\n",
    "  - confidence = 1.00\n",
    "  - lift = 1.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef59b37-5429-42b9-a45c-56ad45a7968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages \n",
    "import numpy as np\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caeaf8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ranch dip', 'Salsa', 'Tortilla chips'],\n",
       " ['Queso', 'Tortilla chips'],\n",
       " ['Potato chips', 'Ranch dip'],\n",
       " ['Salsa', 'Tortilla chips'],\n",
       " ['Queso', 'Salsa', 'Tortilla chips'],\n",
       " ['Pita chips', 'Ranch dip'],\n",
       " ['Guacamole', 'Tortilla chips'],\n",
       " ['Guacamole', 'Queso', 'Salsa', 'Tortilla chips'],\n",
       " ['Pita chips', 'Salsa']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the transactions dataset \n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Loading the data\n",
    "def load_dataset(path_to_data):\n",
    "    transactions = []\n",
    "    with open(path_to_data, 'r') as fid:\n",
    "        for lines in fid:\n",
    "            for line in fid:\n",
    "                # Split each line by commas to extract individual items in the transaction\n",
    "                transaction = line.strip().split(',')\n",
    "                transactions.append(transaction)\n",
    "    return transactions\n",
    "\n",
    "path_to_data = \"transactions_data.txt\"  \n",
    "dataset = load_dataset(path_to_data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c4cadf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "     support                        itemsets\n",
      "0   0.222222                     (Guacamole)\n",
      "1   0.222222                    (Pita chips)\n",
      "2   0.333333                         (Queso)\n",
      "3   0.333333                     (Ranch dip)\n",
      "4   0.555556                         (Salsa)\n",
      "5   0.666667                (Tortilla chips)\n",
      "6   0.222222     (Tortilla chips, Guacamole)\n",
      "7   0.222222                  (Queso, Salsa)\n",
      "8   0.333333         (Queso, Tortilla chips)\n",
      "9   0.444444         (Tortilla chips, Salsa)\n",
      "10  0.222222  (Queso, Tortilla chips, Salsa)\n",
      "\n",
      "Association Rules:\n",
      "               antecedents              consequents  antecedent support  \\\n",
      "0              (Guacamole)         (Tortilla chips)            0.222222   \n",
      "1                  (Queso)                  (Salsa)            0.333333   \n",
      "2                  (Queso)         (Tortilla chips)            0.333333   \n",
      "3         (Tortilla chips)                  (Queso)            0.666667   \n",
      "4         (Tortilla chips)                  (Salsa)            0.666667   \n",
      "5                  (Salsa)         (Tortilla chips)            0.555556   \n",
      "6  (Queso, Tortilla chips)                  (Salsa)            0.333333   \n",
      "7           (Queso, Salsa)         (Tortilla chips)            0.222222   \n",
      "8  (Tortilla chips, Salsa)                  (Queso)            0.444444   \n",
      "9                  (Queso)  (Tortilla chips, Salsa)            0.333333   \n",
      "\n",
      "   consequent support   support  confidence  lift  leverage  conviction  \\\n",
      "0            0.666667  0.222222    1.000000   1.5  0.074074         inf   \n",
      "1            0.555556  0.222222    0.666667   1.2  0.037037    1.333333   \n",
      "2            0.666667  0.333333    1.000000   1.5  0.111111         inf   \n",
      "3            0.333333  0.333333    0.500000   1.5  0.111111    1.333333   \n",
      "4            0.555556  0.444444    0.666667   1.2  0.074074    1.333333   \n",
      "5            0.666667  0.444444    0.800000   1.2  0.074074    1.666667   \n",
      "6            0.555556  0.222222    0.666667   1.2  0.037037    1.333333   \n",
      "7            0.666667  0.222222    1.000000   1.5  0.074074         inf   \n",
      "8            0.333333  0.222222    0.500000   1.5  0.074074    1.333333   \n",
      "9            0.444444  0.222222    0.666667   1.5  0.074074    1.666667   \n",
      "\n",
      "   zhangs_metric  \n",
      "0       0.428571  \n",
      "1       0.250000  \n",
      "2       0.500000  \n",
      "3       1.000000  \n",
      "4       0.500000  \n",
      "5       0.375000  \n",
      "6       0.250000  \n",
      "7       0.428571  \n",
      "8       0.600000  \n",
      "9       0.500000  \n"
     ]
    }
   ],
   "source": [
    "# Transform the data to a format suitable for the apriori function\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply the apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate the association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81071e13-02cb-40f2-8210-5e420bf572ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
